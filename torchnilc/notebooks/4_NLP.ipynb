{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP\n",
    "\n",
    "## Classificando documentos usando BoW\n",
    "\n",
    "Primeiro vamos dar uma revisada no softmax pra ver se entedemos bem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.6614,  0.2669,  0.0617,  0.6213, -0.4519])\n",
      "tensor([0.2847, 0.1919, 0.1563, 0.2735, 0.0935])\n",
      "tensor(1.)\n",
      "tensor([-1.2563, -1.6507, -1.8559, -1.2963, -2.3695])\n",
      "tensor([-1.2563, -1.6507, -1.8559, -1.2963, -2.3695])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# Softmax is also in torch.nn.functional\n",
    "data = torch.randn(5)\n",
    "print(data)\n",
    "print(F.softmax(data, dim=0))\n",
    "print(F.softmax(data, dim=0).sum())  # Sums to 1 because it is a distribution!\n",
    "print(F.log_softmax(data, dim=0))  # theres also log_softmax\n",
    "print(F.softmax(data, dim=0).log())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O': 0, 'Henrico': 1, 'é': 2, 'um': 3, 'cara': 4, 'legal': 5, 'Give': 6, 'it': 7, 'to': 8, 'me': 9, 'Bolsonaro': 10, 'uma': 11, 'pessoa': 12, 'especial': 13, 'No': 14, 'is': 15, 'not': 16, 'a': 17, 'good': 18, 'idea': 19, 'get': 20, 'lost': 21, 'at': 22, 'sea': 23, 'ronaldinho': 24, 'gaúcho': 25, 'misterioso': 26, '.': 27, 'on': 28}\n"
     ]
    }
   ],
   "source": [
    "data = [(\"O Henrico é um cara legal\".split(), \"PORTUGUESE\"),\n",
    "        (\"Give it to me\".split(), \"ENGLISH\"),\n",
    "        (\"O Bolsonaro é uma pessoa especial\".split(), \"PORTUGUESE\"),\n",
    "        (\"No it is not a good idea to get lost at sea\".split(), \"ENGLISH\")]\n",
    "\n",
    "test_data = [(\"O ronaldinho gaúcho é um cara misterioso .\".split(), \"PORTUGUESE\"),\n",
    "             (\"it is lost on me\".split(), \"ENGLISH\")]\n",
    "\n",
    "# word_to_ix maps each word in the vocab to a unique integer, which will be its\n",
    "# index into the Bag of words vector\n",
    "word_to_ix = {}\n",
    "label_to_ix = {\"PORTUGUESE\": 0, \"ENGLISH\": 1}\n",
    "\n",
    "for sent, _ in data + test_data:\n",
    "    for word in sent:\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix)\n",
    "print(word_to_ix)\n",
    "\n",
    "VOCAB_SIZE = len(word_to_ix)\n",
    "NUM_LABELS = len(label_to_ix)\n",
    "\n",
    "\n",
    "class BoWClassifier(nn.Module):  # inheriting from nn.Module!\n",
    "\n",
    "    def __init__(self, num_labels, vocab_size):\n",
    "        # calls the init function of nn.Module.  Dont get confused by syntax,\n",
    "        # just always do it in an nn.Module\n",
    "        super().__init__()\n",
    "\n",
    "        # Define the parameters that you will need.  In this case, we need A and b,\n",
    "        # the parameters of the affine mapping.\n",
    "        # Torch defines nn.Linear(), which provides the affine map.\n",
    "        # Make sure you understand why the input dimension is vocab_size\n",
    "        # and the output is num_labels!\n",
    "        self.linear = nn.Linear(vocab_size, 100)\n",
    "        self.conv_1d = nn.Conv1d(1, 50, 5)\n",
    "        self.output = nn.Linear(96*50, num_labels)\n",
    "        # NOTE! The non-linearity log softmax does not have parameters! So we don't need\n",
    "        # to worry about that here\n",
    "\n",
    "    def forward(self, bow_vec):\n",
    "        # Pass the input through the linear layer,\n",
    "        # then pass that through log_softmax.\n",
    "        # Many non-linearities and other functions are in torch.nn.functional\n",
    "        print('input:', bow_vec.shape)\n",
    "        \n",
    "        # (bs, doc_size) -> (bs, 100)  \n",
    "        x = self.linear(bow_vec)\n",
    "        x = torch.relu(x)\n",
    "#         print('linear:', x.shape)\n",
    "\n",
    "        # (bs, 100) -> (bs, 1, 100) \n",
    "        x = x.unsqueeze(1)\n",
    "#         print('linear:', x.shape)\n",
    "        \n",
    "        # (bs, 1, 100) -> (bs, 96, 50) \n",
    "        x = self.conv_1d(x)\n",
    "#         print('conv:', x.shape)\n",
    "        x = torch.sigmoid(x)\n",
    "        \n",
    "        # (bs, 96, 50)  -> (bs, 96*50) \n",
    "        x = x.view(1, -1)\n",
    "#         print('flatted', x.shape)\n",
    "        \n",
    "        # (bs, 96*50)  -> (bs, 2) \n",
    "        x = self.output(x)\n",
    "#         print('output', x.shape)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "def make_bow_vector(sentence, word_to_ix):\n",
    "    vec = torch.zeros(len(word_to_ix))\n",
    "    for word in sentence:\n",
    "        vec[word_to_ix[word]] += 1\n",
    "    return vec.view(1, -1)\n",
    "\n",
    "\n",
    "def make_target(label, label_to_ix):\n",
    "    return torch.LongTensor([label_to_ix[label]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([0])\n"
     ]
    }
   ],
   "source": [
    "print(make_bow_vector(data[0][0], word_to_ix))\n",
    "print(make_target(data[0][1], label_to_ix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BoWClassifier(NUM_LABELS, VOCAB_SIZE)\n",
    "\n",
    "# the model knows its parameters.  The first output below is A, the second is b.\n",
    "# Whenever you assign a component to a class variable in the __init__ function\n",
    "# of a module, which was done with the line\n",
    "# self.linear = nn.Linear(...)\n",
    "# Then through some Python magic from the PyTorch devs, your module\n",
    "# (in this case, BoWClassifier) will store knowledge of the nn.Linear's parameters\n",
    "# for param in model.parameters():\n",
    "#     print(param)\n",
    "\n",
    "# To run the model, pass in a BoW vector\n",
    "# Here we don't need to train, so the code is wrapped in torch.no_grad()\n",
    "# with torch.no_grad():\n",
    "#     sample = data[1]\n",
    "#     bow_vector = make_bow_vector(sample[0], word_to_ix)\n",
    "#     log_probs = model(bow_vector)\n",
    "# #     print(log_probs.exp())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nossa entrada é um bag of words, então \n",
    "\n",
    "    doc_0 = [count(v_0), count(v_1), count(v_2), ..., count(v_n)]\n",
    "    doc_1 = [count(v_0), count(v_1), count(v_2), ..., count(v_n)]\n",
    "    \n",
    "Nossa rede neural é uma camda linear seguida por um log_softmax (é uma regressão logística!): \n",
    "\n",
    "    net = log_softmax(linear(doc))\n",
    "\n",
    "Bora treinar uma pouco essa rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1158,  0.0266, -0.1454, -0.1183,  0.0824,  0.0964, -0.0587,  0.1547,\n",
      "        -0.0247, -0.1376, -0.1316, -0.1065, -0.0853, -0.1436,  0.0178,  0.0670,\n",
      "         0.1633,  0.1156,  0.0214, -0.0359, -0.1628, -0.1722,  0.1088,  0.1614,\n",
      "         0.0828, -0.0490,  0.0283, -0.1709, -0.1197, -0.0069,  0.0068,  0.1753,\n",
      "        -0.1133,  0.0627, -0.0942,  0.0265, -0.0919, -0.1255,  0.1599, -0.0419,\n",
      "        -0.0641,  0.1540, -0.1528,  0.1412,  0.0783,  0.0560, -0.0193, -0.1119,\n",
      "         0.1042,  0.0335,  0.1507, -0.1181,  0.1835,  0.1532,  0.0682,  0.1418,\n",
      "         0.1370,  0.0172, -0.1805, -0.1003,  0.1508,  0.1235, -0.0754,  0.0786,\n",
      "        -0.0759,  0.1337,  0.1521,  0.1123, -0.1392, -0.0181, -0.0108, -0.1767,\n",
      "        -0.0256, -0.0802, -0.1432,  0.1590, -0.0405, -0.0938,  0.0795,  0.1531,\n",
      "         0.0783,  0.0219,  0.1157, -0.0415, -0.0862,  0.0917,  0.0542, -0.1832,\n",
      "         0.1057,  0.0323,  0.0185,  0.0044, -0.0622,  0.1230,  0.1404,  0.0220,\n",
      "        -0.0044, -0.1165, -0.0451, -0.1430], grad_fn=<SelectBackward>)\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "# Print the matrix column corresponding to \"cara\"\n",
    "print(next(model.parameters())[:, word_to_ix[\"cara\"]])\n",
    "\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# Usually you want to pass over the training data several times.\n",
    "# 100 is much bigger than on a real data set, but real datasets have more than\n",
    "# two instances.  Usually, somewhere between 5 and 30 epochs is reasonable.\n",
    "for epoch in range(100):\n",
    "    for sentence, label in data:\n",
    "        # Step 1. Remember that PyTorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 2. Make our BOW vector and also we must wrap the target in a\n",
    "        # Tensor as an integer. For example, if the target is PORTUGUESE, then\n",
    "        # we wrap the integer 0. The loss function then knows that the 0th\n",
    "        # element of the log probabilities is the log probability\n",
    "        # corresponding to PORTUGUESE\n",
    "        bow_vec = make_bow_vector(sentence, word_to_ix)\n",
    "        target = make_target(label, label_to_ix)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        log_probs = model(bow_vec)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        # calling optimizer.step()\n",
    "        loss = loss_function(log_probs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['O', 'ronaldinho', 'gaúcho', 'é', 'um', 'cara', 'misterioso', '.'],\n",
       "  'PORTUGUESE'),\n",
       " (['it', 'is', 'lost', 'on', 'me'], 'ENGLISH')]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL:\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "tensor(0)\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n",
      "tensor(1)\n",
      "tensor([ 0.1403,  0.0765, -0.1410,  0.0054,  0.1467,  0.0964, -0.0587,  0.0905,\n",
      "        -0.0247, -0.1312, -0.0811,  0.0043, -0.0376, -0.1154,  0.0855,  0.0670,\n",
      "         0.2005,  0.1902,  0.0642, -0.0359, -0.0708, -0.0598,  0.2556,  0.2551,\n",
      "         0.1599, -0.1070,  0.0283, -0.1709, -0.0661, -0.0069,  0.0068,  0.1753,\n",
      "        -0.0231,  0.1047, -0.0838,  0.0330, -0.0919, -0.1255,  0.2241, -0.0419,\n",
      "         0.0148,  0.1437, -0.1528,  0.1412,  0.1680,  0.1605, -0.0193, -0.1119,\n",
      "         0.1922,  0.0335,  0.1507, -0.1181,  0.2724,  0.1532,  0.0682,  0.2386,\n",
      "         0.1370,  0.0172, -0.1805, -0.0592,  0.2622,  0.2096, -0.0754,  0.1752,\n",
      "        -0.0224,  0.2496,  0.2783,  0.1123, -0.1052,  0.0211, -0.0778, -0.1767,\n",
      "        -0.0744, -0.0255, -0.0644,  0.2498, -0.0233, -0.0327,  0.2448,  0.1526,\n",
      "         0.1601,  0.1163,  0.1157, -0.0415, -0.0862,  0.1182,  0.0560, -0.1832,\n",
      "         0.1301,  0.1076,  0.0768,  0.0044,  0.0051,  0.1604,  0.2262,  0.0220,\n",
      "         0.0523, -0.1113, -0.0088, -0.1430], grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print('EVAL:')\n",
    "    for instance, label in test_data:\n",
    "        bow_vec = make_bow_vector(instance, word_to_ix)\n",
    "        log_probs = model(bow_vec)\n",
    "        print(torch.argmax(log_probs))\n",
    "\n",
    "# Index corresponding to Portuguese goes up, English goes down!\n",
    "print(next(model.parameters())[:, word_to_ix[\"cara\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'Henrico', 'é', 'um', 'cara', 'legal', 'Give', 'it', 'to', 'me', 'Bolsonaro', 'uma', 'pessoa', 'especial', 'No', 'is', 'not', 'a', 'good', 'idea', 'get', 'lost', 'at', 'sea', 'ronaldinho', 'gaúcho', 'misterioso', '.', 'on']\n",
      "input: torch.Size([1, 29])\n",
      "linear: torch.Size([1, 100])\n",
      "linear: torch.Size([1, 1, 100])\n",
      "conv: torch.Size([1, 50, 96])\n",
      "flatted torch.Size([1, 4800])\n",
      "output torch.Size([1, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ENGLISH'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(list(word_to_ix.keys()))\n",
    "tmp = make_bow_vector('O legal is not good .'.split(), word_to_ix)\n",
    "out = model(tmp)\n",
    "inv_label_to_ix = dict(zip(label_to_ix.values(), label_to_ix.keys()))\n",
    "inv_label_to_ix[out.argmax().item()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de língua com a bíblia sagrada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biblia-sagrada-pt.txt\r\n"
     ]
    }
   ],
   "source": [
    "# a biblia tá armazenada em data/biblia-sagrada-pt.txt\n",
    "!ls ../../data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bíblia sagrada', 'tradução: joão ferreira de almeida', 'edição revista e corrigida', 'antigo testamento', 'gênesis', 'gênesis 1', '1 no princípio criou deus os céus e a terra.', '2 a terra era sem forma e vazia; e havia trevas sobre a face do abismo, mas o espírito de deus pairava sobre a face das águas.', '3 disse deus: haja luz. e houve luz.', '4 viu deus que a luz era boa; e fez separação entre a luz e as trevas.']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk import ToktokTokenizer\n",
    "\n",
    "tokenizer = ToktokTokenizer()\n",
    "\n",
    "def read_biblia(fpath):\n",
    "    text = []\n",
    "    with open(fpath, 'r', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip().lower()\n",
    "            if line:\n",
    "                text.append(line)\n",
    "    return text\n",
    "\n",
    "dataset = read_biblia('../../data/biblia-sagrada-pt.txt')\n",
    "print(dataset[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['antigo testamento', 'gênesis', 'gênesis 1', '1 no princípio criou deus os céus e a terra.', '2 a terra era sem forma e vazia; e havia trevas sobre a face do abismo, mas o espírito de deus pairava sobre a face das águas.', '3 disse deus: haja luz. e houve luz.', '4 viu deus que a luz era boa; e fez separação entre a luz e as trevas.', '5 e deus chamou à luz dia, e às trevas noite. e foi a tarde e a manhã, o dia primeiro.', '6 e disse deus: haja um firmamento no meio das águas, e haja separação entre águas e águas.', '7 fez, pois, deus o firmamento, e separou as águas que estavam debaixo do firmamento das que estavam por cima do firmamento. e assim foi.']\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset[3:]\n",
    "print(dataset[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<bos>', 'antigo', 'testamento', '<eos>', '<bos>', 'gênesis', '<eos>', '<bos>', 'gênesis', '1', '<eos>', '<bos>', '1', 'no', 'princípio', 'criou', 'deus', 'os', 'céus', 'e', 'a', 'terra', '.', '<eos>', '<bos>', '2', 'a', 'terra', 'era', 'sem']\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = []\n",
    "for text in dataset:\n",
    "    tokenized_dataset.extend(['<bos>'] + tokenizer.tokenize(text) + ['<eos>'])\n",
    "print(tokenized_dataset[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bora implementar um modelo simples de trigramas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['<bos>', 'antigo'], 'testamento'), (['antigo', 'testamento'], '<eos>'), (['testamento', '<eos>'], '<bos>')]\n"
     ]
    }
   ],
   "source": [
    "CONTEXT_SIZE = 2\n",
    "EMBEDDING_DIM = 3\n",
    "\n",
    "# build a list of tuples.  Each tuple is ([ word_i-2, word_i-1 ], target word)\n",
    "trigrams = [(\n",
    "                [tokenized_dataset[i], tokenized_dataset[i + 1]], \n",
    "                 tokenized_dataset[i + 2]\n",
    "            )\n",
    "            for i in range(len(tokenized_dataset) - 2)]\n",
    "# print the first 3, just so you can see what they look like\n",
    "print(trigrams[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 923673\n",
      "Vocab size: 30462\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "vocab = Counter(tokenized_dataset).most_common(100000)\n",
    "word_to_ix = {word: i+1 for i, (word, _) in enumerate(vocab)}\n",
    "\n",
    "print('Dataset size:', len(trigrams))\n",
    "print('Vocab size:', len(vocab))  # Como diminuir?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGramLanguageModeler(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size, hidden_size=30):\n",
    "        super(NGramLanguageModeler, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(context_size * embedding_dim, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs)\n",
    "        x = embeds.view(embeds.shape[0], -1)\n",
    "        out = F.relu(self.linear1(x))\n",
    "        out = self.linear2(out)\n",
    "        log_probs = F.log_softmax(out, dim=1)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "tigrams_batches = []\n",
    "batch_size = 64\n",
    "batch = []\n",
    "for i, (context, target) in enumerate(trigrams):\n",
    "#     print(context)\n",
    "    if i % batch_size == 0:\n",
    "        if len(batch) > 0 :\n",
    "            tigrams_batches.append(batch)\n",
    "        batch = []\n",
    "    batch.append((context, target))\n",
    "\n",
    "# print(tigrams_batches[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64]\n"
     ]
    }
   ],
   "source": [
    "print(list(map(len, tigrams_batches)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[84226.86968231201]31/14432) 5.836119\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "loss_function = nn.NLLLoss()\n",
    "model = NGramLanguageModeler(len(vocab)+1, 10, CONTEXT_SIZE, hidden_size=10)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "def get_list_of_ids(context, word_to_ix):\n",
    "    list_of_ids = []\n",
    "    for w in context:\n",
    "        if w in word_to_ix:\n",
    "            list_of_ids.append(word_to_ix[w])\n",
    "        else:\n",
    "            list_of_ids.append(0)\n",
    "    return list_of_ids\n",
    "\n",
    "def get_target_id(target, word_to_ix):\n",
    "    target_word_id = 0\n",
    "    if target in word_to_ix:\n",
    "        target_word_id = word_to_ix[target]\n",
    "    return target_word_id\n",
    "\n",
    "\n",
    "for epoch in range(1):\n",
    "    total_loss = 0\n",
    "    for i, x in enumerate(tigrams_batches):\n",
    "        \n",
    "        context, target = zip(*x)\n",
    "        \n",
    "        #print(len(context))\n",
    "        \n",
    "        # Step 1. Prepare the inputs to be passed to the model (i.e, turn the words\n",
    "        # into integer indices and wrap them in tensors)\n",
    "        list_of_ids = [get_list_of_ids(c, word_to_ix) for c in context] \n",
    "        context_idxs = torch.tensor(list_of_ids, dtype=torch.long) \n",
    "\n",
    "        # Step 2. Recall that torch *accumulates* gradients. Before passing in a\n",
    "        # new instance, you need to zero out the gradients from the old\n",
    "        # instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 3. Run the forward pass, getting log probabilities over next\n",
    "        # words\n",
    "        log_probs = model(context_idxs)\n",
    "\n",
    "        # Step 4. Compute your loss function. (Again, Torch wants the target\n",
    "        # word wrapped in a tensor)\n",
    "        target_word_ids = torch.tensor([get_target_id(t, word_to_ix) for t in target], dtype=torch.long)\n",
    "#         print(target_word_ids)\n",
    "        \n",
    "        loss = loss_function(log_probs, target_word_ids)\n",
    "\n",
    "        # Step 5. Do the backward pass and update the gradient\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Get the Python number from a 1-element Tensor by calling tensor.item()\n",
    "        total_loss += loss.item()\n",
    "        print('Epoch %d - Loss (%d/%d) %f' % (epoch+1, i, len(tigrams_batches), total_loss / (i+1)), end='\\r')\n",
    "              \n",
    "    losses.append(total_loss)\n",
    "print(losses)  # The loss decreased every iteration over the training data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1,  6,  8,  5,  0, 10,  2,  7, 11, 20])\n",
      "['that', 'of', 'spirits', 'is', 'rules', 'effect,', 'directed', 'programs', 'a']\n"
     ]
    }
   ],
   "source": [
    "start_context = ['e', 'jesus']\n",
    "id_to_word = dict(zip(word_to_ix.values(), word_to_ix.keys()))\n",
    "\n",
    "list_of_ids = get_list_of_ids(['e', 'jesus'], word_to_ix)\n",
    "context_idxs = torch.tensor([list_of_ids], dtype=torch.long)\n",
    "_, pred_idx = model(context_idxs).topk(10, dim=-1)\n",
    "print(pred_idx[0].data)\n",
    "\n",
    "print([id_to_word[i.item()] for i in pred_idx[0].data if i > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jesus disse , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , ,\n"
     ]
    }
   ],
   "source": [
    "start_context = ['jesus', 'disse']\n",
    "generated_text = [start_context[0]]\n",
    "for i in range(100):\n",
    "        list_of_ids = get_list_of_ids(start_context, word_to_ix)\n",
    "        context_idxs = torch.tensor([list_of_ids], dtype=torch.long)\n",
    "        pred_id = torch.argmax(model(context_idxs))\n",
    "        \n",
    "        if pred_id.item() == 0:\n",
    "            pred_word = '<unk>'\n",
    "        else:\n",
    "            pred_word = id_to_word[pred_id.item()]\n",
    "        start_context = [start_context[1], pred_word]\n",
    "        generated_text.append(start_context[0])\n",
    "\n",
    "print(' '.join(generated_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Implementando CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['We', 'are', 'to', 'study'], 'about'), (['are', 'about', 'study', 'the'], 'to'), (['about', 'to', 'the', 'idea'], 'study'), (['to', 'study', 'idea', 'of'], 'the'), (['study', 'the', 'of', 'a'], 'idea')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([13, 12, 33, 28])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONTEXT_SIZE = 2  # 2 words to the left, 2 to the right\n",
    "raw_text = \"\"\"We are about to study the idea of a computational process.\n",
    "Computational processes are abstract beings that inhabit computers.\n",
    "As they evolve, processes manipulate other abstract things called data.\n",
    "The evolution of a process is directed by a pattern of rules\n",
    "called a program. People create programs to direct processes. In effect,\n",
    "we conjure the spirits of the computer with our spells.\"\"\".split()\n",
    "\n",
    "# By deriving a set from `raw_text`, we deduplicate the array\n",
    "vocab = set(raw_text)\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
    "data = []\n",
    "for i in range(2, len(raw_text) - 2):\n",
    "    context = [raw_text[i - 2], raw_text[i - 1],\n",
    "               raw_text[i + 1], raw_text[i + 2]]\n",
    "    target = raw_text[i]\n",
    "    data.append((context, target))\n",
    "print(data[:5])\n",
    "\n",
    "\n",
    "class CBOW(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, emb_size):\n",
    "        self.embeddings = nn.Embedding(vocab_size, emb_size)\n",
    "        self.lin_out = nn.Linear(emb_size, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # (bs, 4, vocab_size) -> (bs, 4, emb_dim)\n",
    "        x = self.emb(x)\n",
    "        # (bs, 4, emb_dim) -> (bs, 4*emb_dim)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        # (bs, 4*emb_dim) -> (bs, vocab_size)\n",
    "        x = self.lin_out(x)\n",
    "        return torch.log_softmax(x, dim=-1)\n",
    "        \n",
    "\n",
    "# create your model and train.  here are some functions to help you make\n",
    "# the data ready for use by your module\n",
    "\n",
    "\n",
    "def make_context_vector(context, word_to_ix):\n",
    "    idxs = [word_to_ix[w] for w in context]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "\n",
    "make_context_vector(data[0][0], word_to_ix)  # example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skipgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context_pairs(tokenized_corpus, word2idx, window_size=3):\n",
    "    idx_pairs = []\n",
    "    # for each sentence\n",
    "    for sentence in tokenized_corpus:\n",
    "        indices = [word2idx[word] for word in sentence]\n",
    "        # for each word, threated as center word\n",
    "        for center_word_pos in range(len(indices)):\n",
    "            # for each window position\n",
    "            for w in range(-window_size, window_size + 1):\n",
    "                context_word_pos = center_word_pos + w\n",
    "                # make soure not jump out sentence\n",
    "                if context_word_pos < 0 or context_word_pos >= len(indices) or center_word_pos == context_word_pos:\n",
    "                    continue\n",
    "                context_word_idx = indices[context_word_pos]\n",
    "                idx_pairs.append((indices[center_word_pos], context_word_idx))\n",
    "    return idx_pairs\n",
    "\n",
    "def create_vocab(tokenized_corpus):\n",
    "    word2idx = {}\n",
    "    for sent in tmp_corpus:\n",
    "        for word in sent:\n",
    "            if word not in word2idx:\n",
    "                word2idx[word] = len(word2idx)\n",
    "    return word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_corpus = ['the quick brown fox jumps over the lazy fox !'.split(), \n",
    "              'this is just another very cool sentence .'.split()]\n",
    "tmp_word2idx = create_vocab(tmp_corpus)\n",
    "pairs_idx = create_skipgrams(tmp_corpus, tmp_word2idx, window_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model idea\n",
    "# (vocab, emb) -> (emb, vocab) -> log softmax -> nll loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
